apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-ollama-openwebui
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  ollama-openwebui.json: |
    {
      "title": "OpenWebUI + Ollama Overview",
      "schemaVersion": 38,
      "version": 1,
      "time": { "from": "now-6h", "to": "now" },
      "templating": {
        "list": [
          { "name": "namespace", "type": "constant", "query": "ai", "current": { "text": "ai", "value": "ai" } },
          { "name": "ollama_pod", "type": "query", "datasource": "Prometheus",
            "query": "label_values(kube_pod_info{namespace=\"ai\", pod=~\"ollama.*\"}, pod)",
            "includeAll": true, "multi": true }
        ]
      },
      "panels": [
        {
          "type": "timeseries",
          "title": "CPU Ollama (cores)",
          "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
          "fieldConfig": { "defaults": { "unit": "cores" } },
          "targets": [
            {
              "datasource": "Prometheus",
              "expr": "sum by (pod) (rate(container_cpu_usage_seconds_total{namespace=\"ai\",pod=~\"$ollama_pod\",container!=\"\",container!=\"POD\"}[5m]))",
              "legendFormat": "{{pod}}"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "Memoria Ollama (Working Set, bytes)",
          "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
          "fieldConfig": { "defaults": { "unit": "bytes" } },
          "targets": [
            {
              "datasource": "Prometheus",
              "expr": "sum by (pod) (container_memory_working_set_bytes{namespace=\"ai\",pod=~\"$ollama_pod\",container!=\"\",container!=\"POD\"})",
              "legendFormat": "{{pod}}"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "Memoria Ollama (% del límite)",
          "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
          "fieldConfig": { "defaults": { "unit": "percent" } },
          "targets": [
            {
              "datasource": "Prometheus",
              "expr": "100 * sum by(pod)(container_memory_working_set_bytes{namespace=\"ai\",pod=~\"$ollama_pod\",container!=\"\",container!=\"POD\"}) / sum by(pod)(kube_pod_container_resource_limits{namespace=\"ai\",resource=\"memory\",pod=~\"$ollama_pod\"})",
              "legendFormat": "{{pod}}"
            }
          ]
        },
        {
          "type": "timeseries",
          "title": "Latencia de inferencia (p95, OpenWebUI vía OTEL)",
          "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
          "fieldConfig": { "defaults": { "unit": "s" } },
          "targets": [
            {
              "datasource": "Prometheus",
              "expr": "histogram_quantile(0.95, sum by (le) (rate(http_server_duration_bucket{job=\"otel-collector\",service_name=\"open-webui\"}[5m])))",
              "legendFormat": "p95"
            }
          ]
        }
      ],
      "annotations": { "list": [] }
    }
